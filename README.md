# ELECTRA FOR IF

## Introduction

Experiment on the usefulness of Large Language Model in the context of Interactive Fiction.

## Acknowledgements

Inspired by the [CIS 700-001 - Interactive Fiction and Text Generation](https://interactive-fiction-class.org/index.html) Course.

## ELECTRA

[**ELECTRA**](https://github.com/google-research/electra) is a method for self-supervised language representation learning. It can be used to pre-train transformer networks using relatively little compute. ELECTRA models are trained to distinguish "real" input tokens vs "fake" input tokens generated by another neural network, similar to the discriminator of a [GAN](https://arxiv.org/pdf/1406.2661.pdf). For a detailed description and experimental results, refer to the original ICLR 2020 paper [ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators](https://openreview.net/pdf?id=r1xMH1BtvB) (Clark et al.). Aureliano Porporato did not take part in the original project in any way.

### Original Project Requirements

* Python 3.7
* [TensorFlow](https://www.tensorflow.org/) _1.15_
* [NumPy](https://numpy.org/) (1.21.2)
* [scikit-learn](https://scikit-learn.org/stable/) (1.0.1) and [SciPy](https://www.scipy.org/) (1.7.3) for computing
  some evaluation metrics only.

## Fine-tuning

The original small model has been finetuned on a subset of the [GLUE](https://gluebenchmark.com/) classification tasks (i.e.: [CoLA](https://nyu-mll.github.io/CoLA/), [SST](https://nlp.stanford.edu/sentiment/index.html), MRPC, [STS](http://ixa2.si.ehu.eus/stswiki/index.php/STSbenchmark), QQP, [MNLI](https://cims.nyu.edu/~sbowman/) [plus [AX](https://gluebenchmark.com/diagnostics) for evaluation], [RTE](https://aclweb.org/aclwiki/Recognizing_Textual_Entailment) and [WNLI](https://cs.nyu.edu/~davise/papers/WinogradSchemas/WS.html)), the [SQuAD 2.0](https://rajpurkar.github.io/SQuAD-explorer/) QA task and the [CoNLL](https://www.clips.uantwerpen.be/conll2000/chunking/) text chunking task. The data were prepared as shown [here](https://github.com/google-research/electra#setup-1). The model was finetuned on the data from all the tasks at once, for 10 epochs.

[comment]: <> (`$DATA_DIR` = `"D:\ELECTRAIFFinetuned\electra"`)

`python run_finetuning.py --data-dir $DATA_DIR --model-name electra_small --hparams finetuning_config.json`

That command took ~40 hours on a single NVIDIA GeForce GTX 1050 Ti.

### Results

The results (test set for chunking, dev set for the other tasks) for the model finetuned in the way described above are reported (ELECTRA-Small-Finetuned). For references, also the result expected for the finetuned original model, as reported [here](https://github.com/google-research/electra#expected-results), are shown (ELECTRA-Small).

|  | MNLI | WNLI | STS | MRPC | Chunking | RTE | QQP | SST | SQuAD 2.0 | CoLA |
| --- | --- | --- | --- | --- | ---  | --- | --- | --- | --- | --- |
| Metrics | Acc | Acc | Pear/Spear | Acc | F1 | Acc | Acc | Acc | EM | MCC |
| ELECTRA-Small | 81.3 | - | -/87.5 |  88.0 | 96.5  | 66.7 | 89.0 | 91.2 | 70.1 | 57.0 |
| ELECTRA-Small-Finetuned | 82.6 | 32.4 | 86.5/86.5 |  86.5 | 96.4 | 71.1 | 90.3 | 89.8 | 70.1 |  49.7 |

## Citation

Original paper:

```
@inproceedings{clark2020electra,
  title = {{ELECTRA}: Pre-training Text Encoders as Discriminators Rather Than Generators},
  author = {Kevin Clark and Minh-Thang Luong and Quoc V. Le and Christopher D. Manning},
  booktitle = {ICLR},
  year = {2020},
  url = {https://openreview.net/pdf?id=r1xMH1BtvB}
}
```

## Finetune ELECTRA on IF dataset

The finetuned small model has been in turn finetuned on various classification tasks. For this, the `classification_if_tasks.py`, `task_if_builder.py` and `configure_if_finetuning.py` scripts has been created. Details on the datasets can be found [here](https://github.com/aporporato/jericho-corpora). To replicate, move each folder in the `IF` one into your `finetuning_data` directory (refer to the [original project](https://github.com/google-research/electra#finetune-electra-on-a-glue--task) for detailed instructions). The model was finetuned on the data from all the tasks at once, for 10 epochs.

```
python run_if_finetuning.py --data-dir $DATA_DIR --model-name electra_small_finetuned --hparams '{"model_size": "small", "task_names": ["npc", "fn", "vn", "wn"]}'
```

That command took ~40 minutes on a single NVIDIA GeForce GTX 1050 Ti.

### Results

The results on test set for the tasks are reported for the newly finetuned model (ELECTRA-Small-IF). For comparison, the result for the original model and for the model finetuned on GLUE tasks are also reported (ELECTRA-Small and ELECTRA-Small-Finetuned respectively, obtained with `"do_train": false` option).

|  | WordNet | VerbNet | FrameNet | Third Person Command |
| --- | --- | --- | --- | --- |
| Metrics | Acc | Acc | Acc | Acc |
| ELECTRA-Small | 0.1 | 5.6 | 1.1 | 0.0 |
| ELECTRA-Small-Finetuned | 0.1 | 1.3 | 14 | 0.8 |
| ELECTRA-Small-IF | 93.7 | 56.2 | 86.2 | 98.1 |

(Note that this number is provided just for a rough estimate).

## Hugging Face `transformers` Model

Due to some difficulties in the conversion of the models from Tensorflow 1.x to version 2.x, an approximation (due to some different configurations, but mostly to the selection of the best performing model aftr√¨er 7 to continue the finetunig on the subsequent task, and the exclusion of the AX task evaluation) of the finetuning process described above has been repeated from scratch on the [Hugging Face ELECTRA small discriminator](https://huggingface.co/google/electra-small-discriminator) model (Transformers 4.17.0). The reported number have been obtained by the best model finetuned using the validation set of the respective task, before finetune the model on the following one.

That process took ~21 hours on an Azure Virtual Machine with 1 K80 GPU (1/2 Physical Card).

The resulting models, eventually finetuned for the recognition of orders given to NPC and WordNet synset classification of the verb in the command, on the whole dataset (train set + test set,  epochs), are available [here](https://huggingface.co/Aureliano/electra-npc) and [here](https://huggingface.co/Aureliano/electra-if), both as `ElectraModel` and `TFElectraModel`.

| | WN | VN | FN | NPC | MNLI | WNLI | STS | MRPC | Chunk | RTE | QQP | SST | SQuAD2 | CoLA |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Metrics | Acc | Acc | Acc | Acc | Acc | Acc | Pear/Spear | Acc | F1 | Acc | Acc | Acc | EM | MCC |
| ELECTRA-Small-IF | 91.2 | 62.6 | 83.5 | 100.0 | 79.9 | 56.3 | 87.3/87.1 | 75.0 | 90.6 | 63.2 | 88.8 | 89.1 | - | 55.3 |
